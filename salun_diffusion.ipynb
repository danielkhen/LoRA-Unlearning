{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52ee8710",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "TORCH_SEED = 69\n",
    "torch.manual_seed(TORCH_SEED)\n",
    "\n",
    "import logging\n",
    "import os\n",
    "\n",
    "os.makedirs('weights', exist_ok=True)\n",
    "run_logger = logging.getLogger('run_logger')\n",
    "file_handler = logging.FileHandler('weights/runs.log')\n",
    "run_logger.addHandler(file_handler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bf77a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.functional import one_hot\n",
    "\n",
    "NUM_WORKERS = 4\n",
    "BATCH_SIZE = 128\n",
    "INPUT_SIZE = 32\n",
    "NUM_CLASSES = 10\n",
    "dataset = datasets.CIFAR10\n",
    "\n",
    "AUGMENTATIONS = (\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    ")\n",
    "\n",
    "NORMALIZATIONS = (\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize( (0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    ")\n",
    "\n",
    "# Load datasets\n",
    "training_data = dataset(root='./data', train=True, download=True, transform=transforms.Compose(AUGMENTATIONS + NORMALIZATIONS))\n",
    "\n",
    "# Load data loaders\n",
    "train_dataloader = DataLoader(training_data, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a2b01d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: 38632323\n"
     ]
    }
   ],
   "source": [
    "import model_factory\n",
    "\n",
    "MODEL_NAME = 'salun-ddpm'\n",
    "\n",
    "# Load model\n",
    "model = model_factory.create_model(MODEL_NAME, NUM_CLASSES, input_size=INPUT_SIZE)\n",
    "\n",
    "trainable_params = sum(param.numel() for param in model.parameters() if param.requires_grad)\n",
    "print(f\"Number of trainable parameters: {trainable_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2256208c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from torch import optim, nn\n",
    "from models.ema import EMAHelper\n",
    "\n",
    "LEARNING_RATE = 2e-4\n",
    "WEIGHT_DECAY = 0\n",
    "BETA1 = 1e-4\n",
    "BETA2 = 0.02\n",
    "TIMESTEPS = 1000\n",
    "EMA_RATE = 0.9999\n",
    "\n",
    "# Load optimizer and criterion\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "ema_helper = EMAHelper(mu=EMA_RATE)\n",
    "ema_helper.register(model)\n",
    "\n",
    "# Linear schedule\n",
    "betas = np.linspace(\n",
    "            BETA1, BETA2, TIMESTEPS, dtype=np.float64\n",
    "        )\n",
    "betas = torch.from_numpy(betas).float().to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de632618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(\n",
    "    model,\n",
    "    x0: torch.Tensor,\n",
    "    t: torch.LongTensor,\n",
    "    c: torch.LongTensor,\n",
    "    e: torch.Tensor,\n",
    "    b: torch.Tensor,\n",
    "    cond_drop_prob=0.1,\n",
    "    keepdim=False,\n",
    "):\n",
    "    a = (1 - b).cumprod(dim=0).index_select(0, t).view(-1, 1, 1, 1)\n",
    "    x = x0 * a.sqrt() + e * (1.0 - a).sqrt()\n",
    "    output = model(x, t.float(), c, cond_drop_prob=cond_drop_prob, mode=\"train\")\n",
    "    if keepdim:\n",
    "        return (e - output).square().sum(dim=(1, 2, 3))\n",
    "    else:\n",
    "        return (e - output).square().sum(dim=(1, 2, 3)).mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f096888a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?epoch/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "SAVE_FILE = 'weights/cifar10-salun.pth'\n",
    "EPOCHS = 200\n",
    "EVAL_EVERY = 5\n",
    "GRAD_CLIP = 1.0\n",
    "\n",
    "model.to('cuda')\n",
    "model.train()\n",
    "\n",
    "test_loss = None\n",
    "test_accuracy = None\n",
    "\n",
    "# Normal training\n",
    "with tqdm(range(EPOCHS), unit='epoch') as pbar:\n",
    "    for epoch in pbar:\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for inputs, labels in train_dataloader:\n",
    "            # Move inputs and labels to the specified device\n",
    "            inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "\n",
    "            batch_size = inputs.shape[0]\n",
    "\n",
    "            # perturb data\n",
    "            t = torch.randint(low=0, high=TIMESTEPS, size=(batch_size // 2 + 1,), device='cuda')\n",
    "            t = torch.cat([t, TIMESTEPS - t - 1], dim=0)[:batch_size]\n",
    "            noise = torch.randn_like(inputs, device='cuda')\n",
    "\n",
    "            # Compute the loss and its gradients\n",
    "            loss = criterion(model, inputs, t, labels, noise, betas)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Adjust learning weights and zero gradients\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # Clip gradients\n",
    "            try:\n",
    "                torch.nn.utils.clip_grad_norm_(\n",
    "                    model.parameters(), GRAD_CLIP\n",
    "                )\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss = running_loss / len(train_dataloader)\n",
    "\n",
    "        if (epoch + 1) % EVAL_EVERY == 0:\n",
    "            run_logger.debug(f'Normal training checkpoint: save_file={SAVE_FILE}, epoch={epoch}, train_loss={train_loss}')\n",
    "            torch.save(model, f'{SAVE_FILE}.checkpoint')\n",
    "\n",
    "        pbar.set_postfix(train_loss=train_loss)\n",
    "\n",
    "run_logger.info(f'Normal training complete: save_file={SAVE_FILE}, train_loss={train_loss}')\n",
    "torch.save(model, SAVE_FILE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
