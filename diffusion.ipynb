{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "044aa744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "TORCH_SEED = 69\n",
    "torch.manual_seed(TORCH_SEED)\n",
    "\n",
    "import logging\n",
    "import os\n",
    "\n",
    "os.makedirs('weights', exist_ok=True)\n",
    "run_logger = logging.getLogger('run_logger')\n",
    "file_handler = logging.FileHandler('weights/runs.log')\n",
    "run_logger.addHandler(file_handler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c11e463",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:01<00:00, 6.84MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 200kB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 1.89MB/s]\n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 4.63MB/s]\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.functional import one_hot\n",
    "\n",
    "NUM_WORKERS = 8\n",
    "BATCH_SIZE = 16\n",
    "INPUT_SIZE = 28\n",
    "NUM_CLASSES = 10\n",
    "dataset = datasets.MNIST\n",
    "\n",
    "AUGMENTATIONS = (\n",
    "        #transforms.Resize(INPUT_SIZE),\n",
    "        # transforms.Resize(INPUT_SIZE + INPUT_SIZE // 4),\n",
    "        # transforms.RandomResizedCrop(INPUT_SIZE, scale=(0.8, 1.0)),\n",
    "        # transforms.RandomHorizontalFlip(),\n",
    ")\n",
    "\n",
    "NORMALIZATIONS = (\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize( (0.5), (0.5))\n",
    ")\n",
    "\n",
    "# Lambda can't be pickled\n",
    "def one_hot_transform(label):\n",
    "    return one_hot(torch.tensor(label), NUM_CLASSES).squeeze()\n",
    "\n",
    "TARGET_TRANSFORM = transforms.Compose([\n",
    "        transforms.Lambda(one_hot_transform),\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "training_data = dataset(root='./data', train=True, download=True, transform=transforms.Compose(AUGMENTATIONS + NORMALIZATIONS), target_transform=TARGET_TRANSFORM)\n",
    "\n",
    "# Load data loaders\n",
    "train_dataloader = DataLoader(training_data, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f97ce5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_factory\n",
    "\n",
    "MODEL_NAME = 'context-unet'\n",
    "\n",
    "# Load model\n",
    "model = model_factory.create_model(MODEL_NAME, NUM_CLASSES, input_size=INPUT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5165a821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: 2650115\n"
     ]
    }
   ],
   "source": [
    "import fine_tuning\n",
    "\n",
    "LORA_RANK = 16\n",
    "LORA_TARGET_REGEXES = ['^(?!init_conv|final_conv).*']\n",
    "\n",
    "# Apply LoRa\n",
    "model = fine_tuning.get_lora_model(model, LORA_RANK, LORA_TARGET_REGEXES)\n",
    "trainable_params = sum(param.numel() for param in model.parameters() if param.requires_grad)\n",
    "print(f\"Number of trainable parameters: {trainable_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19a7620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model from save file\n",
    "SAVE_FILE = 'weights/model.pth'\n",
    "model = torch.load(SAVE_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42ed156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge and unload LoRa\n",
    "model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad77285",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim, nn\n",
    "\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 0\n",
    "BETA1 = 1e-4\n",
    "BETA2 = 0.02\n",
    "TIMESTEPS = 500\n",
    "\n",
    "# Load optimizer and criterion\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "b_t = torch.linspace(BETA1, BETA2, TIMESTEPS + 1).to('cuda')\n",
    "a_t = 1 - b_t\n",
    "ab_t = torch.cumprod(a_t, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6caac209",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lr=None, train_loss=None:   0%|          | 0/50 [00:15<?, ?epoch/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 44040, 41000, 44944, 40536, 10856, 21500, 46268, 46700) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1284\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1284\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\queues.py:114\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll(timeout):\n\u001b[1;32m--> 114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[0;32m     20\u001b[0m     running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m---> 22\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Move inputs and labels to the specified device\u001b[39;49;00m\n\u001b[0;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# perturb data\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    731\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 733\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    739\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1491\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1488\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data, worker_id)\n\u001b[0;32m   1490\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1491\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1492\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1494\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1453\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1449\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1450\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1451\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1452\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1453\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1454\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1455\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1297\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1296\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[1;32m-> 1297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1299\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   1300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[0;32m   1301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 44040, 41000, 44944, 40536, 10856, 21500, 46268, 46700) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import LinearLR\n",
    "from tqdm import tqdm\n",
    "\n",
    "SAVE_FILE = 'weights/mnist-unetL16.pth'\n",
    "EPOCHS = 50\n",
    "EVAL_EVERY = 5\n",
    "LABELS_MASK_P = 0.9\n",
    "LR_END_FACTOR = 1e-2\n",
    "\n",
    "lr_scheduler = LinearLR(optimizer, start_factor=1, end_factor=LR_END_FACTOR, total_iters=EPOCHS)\n",
    "model.to('cuda')\n",
    "model.train()\n",
    "\n",
    "test_loss = None\n",
    "test_accuracy = None\n",
    "\n",
    "# Normal training\n",
    "with tqdm(range(EPOCHS), unit='epoch', desc='lr=None, train_loss=None') as pbar:\n",
    "    for epoch in pbar:\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for inputs, labels in train_dataloader:\n",
    "            # Move inputs and labels to the specified device\n",
    "            inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "\n",
    "            # perturb data\n",
    "            noise = torch.randn_like(inputs, device='cuda')\n",
    "            t = torch.randint(1, TIMESTEPS + 1, (inputs.shape[0], ), device='cuda')\n",
    "            sqrt_ab_t = ab_t[t].sqrt().view(-1, 1, 1, 1)\n",
    "            sqrt_one_minus_ab_t = (1 - ab_t[t]).sqrt().view(-1, 1, 1, 1)\n",
    "            x_pert = sqrt_ab_t * inputs + sqrt_one_minus_ab_t * noise\n",
    "\n",
    "            # Randomly mask labels\n",
    "            labels = labels*torch.bernoulli(torch.ones((labels.shape[0], 1), device='cuda')*LABELS_MASK_P)\n",
    "\n",
    "            # Predict noise\n",
    "            outputs = model(x_pert, t / TIMESTEPS, labels)\n",
    "\n",
    "            # Compute the loss and its gradients\n",
    "            loss = criterion(outputs, noise)\n",
    "            running_loss += loss.item()\n",
    "            loss.backward()\n",
    "            \n",
    "            # Adjust learning weights and zero gradients\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        train_loss = running_loss / len(train_dataloader)\n",
    "\n",
    "        lr_scheduler.step()\n",
    "        lr = lr_scheduler.get_last_lr()[0]\n",
    "\n",
    "        if (epoch + 1) % EVAL_EVERY == 0:\n",
    "            run_logger.debug(f'Normal training checkpoint: save_file={SAVE_FILE}, epoch={epoch}, train_loss={train_loss}')\n",
    "            torch.save(model, f'{SAVE_FILE}.checkpoint')\n",
    "\n",
    "        pbar.set_postfix(lr=lr, train_loss=train_loss)\n",
    "\n",
    "run_logger.info(f'Normal training complete: save_file={SAVE_FILE}, train_loss={train_loss}')\n",
    "torch.save(model, SAVE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a958f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x200 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from eval import sample\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Number of samples to generate\n",
    "SAMPLES_PER_CLASS = 10\n",
    "\n",
    "# Sampling parameters\n",
    "with torch.no_grad():\n",
    "    samples = sample(model, NUM_CLASSES, SAMPLES_PER_CLASS, INPUT_SIZE, TIMESTEPS, a_t, b_t, ab_t)\n",
    "\n",
    "    fig, axes = plt.subplots(NUM_CLASSES + 1, SAMPLES_PER_CLASS, figsize=((NUM_CLASSES + 1) * 1.5, SAMPLES_PER_CLASS * 1.5))\n",
    "    \n",
    "    for idx, ax in enumerate(axes.flatten()):\n",
    "        img = np.transpose(samples[idx], (1, 2, 0))\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75640ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "FORGET_LABEL = 0\n",
    "\n",
    "training_data = dataset(root='./data', train=True, download=True, transform=transforms.Compose(NORMALIZATIONS), target_transform=TARGET_TRANSFORM)\n",
    "\n",
    "# Class forgetting\n",
    "original_trainset = training_data\n",
    "unlearning_data = Subset(original_trainset, [i for i, (_, label) in enumerate(original_trainset) if label.argmax() == FORGET_LABEL])\n",
    "training_data = Subset(original_trainset, [i for i, (_, label) in enumerate(original_trainset) if label.argmax() != FORGET_LABEL])\n",
    "\n",
    "# Load data loaders\n",
    "train_dataloader = DataLoader(training_data, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=True)\n",
    "unlearn_dataloader = DataLoader(unlearning_data, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bcd2713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "for _, b in unlearn_dataloader:\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455edca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import eval\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "SAVE_FILE = 'weights/modelNG10000.pth'\n",
    "EPOCHS = 200\n",
    "EVAL_EVERY = 5\n",
    "UNLEAN_GRAD_METHOD = 'both' # 'both' or 'ascent\n",
    "\n",
    "model.to('cuda')\n",
    "model.train()\n",
    "\n",
    "test_loss = None\n",
    "test_accuracy = None\n",
    "\n",
    "# NegGrad unlearning\n",
    "with tqdm(range(EPOCHS), unit='epoch', desc='retain_accuracy=None, forget_accuracy=None, test_accuracy=None, retain_loss=None, forget_loss=None, test_loss=None') as pbar:\n",
    "    for epoch in pbar:\n",
    "        retain_running_loss, forget_running_loss = 0.0, 0.0\n",
    "        retain_correct_predictions, forget_correct_predictions = 0, 0\n",
    "        retain_total_predictions, forget_total_predictions = 0, 0\n",
    "\n",
    "        for (retain_inputs, retain_labels), (forget_inputs, forget_labels) in zip(train_dataloader, unlearn_dataloader):\n",
    "            # Move inputs and labels to the specified device\n",
    "            retain_inputs, retain_labels = retain_inputs.to('cuda'), retain_labels.to('cuda')\n",
    "            forget_inputs, forget_labels = forget_inputs.to('cuda'), forget_labels.to('cuda')\n",
    "\n",
    "            # Compute predictions\n",
    "            retain_outputs = model(retain_inputs)\n",
    "            forget_outputs = model(forget_inputs)\n",
    "            _, retain_predictions = torch.max(retain_outputs.data, 1)\n",
    "            _, forget_predictions = torch.max(forget_outputs.data, 1)\n",
    "\n",
    "            # Update the running total of correct predictions and samples\n",
    "            retain_correct_predictions += (retain_predictions == retain_labels).sum().item()\n",
    "            forget_correct_predictions += (forget_predictions == forget_labels).sum().item()\n",
    "            retain_total_predictions += retain_labels.size(0)\n",
    "            forget_total_predictions += forget_labels.size(0)\n",
    "\n",
    "            # Compute the loss and its gradients\n",
    "            retain_loss = criterion(retain_outputs, retain_labels)\n",
    "            forget_loss = criterion(forget_outputs, forget_labels)\n",
    "            retain_running_loss += retain_loss.item()\n",
    "            forget_running_loss += forget_loss.item()\n",
    "            (-1.0 * forget_loss).backward()\n",
    "\n",
    "            if UNLEAN_GRAD_METHOD == 'both':\n",
    "                retain_loss.backward()\n",
    "\n",
    "            # Adjust learning weights and zero gradients\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # Calculate the average loss and accuracy\n",
    "        retain_loss = retain_running_loss / len(train_dataloader)\n",
    "        forget_loss = forget_running_loss / len(train_dataloader)\n",
    "        retain_accuracy = 100 * retain_correct_predictions / retain_total_predictions\n",
    "        forget_accuracy = 100 * forget_correct_predictions / forget_total_predictions\n",
    "        \n",
    "        test_loss, test_accuracy = eval.test(model, test_dataloader, criterion)\n",
    "\n",
    "        pbar.set_postfix(test_loss=test_loss, forget_loss=forget_loss, retain_loss=retain_loss, test_accuracy=test_accuracy, forget_accuracy=forget_accuracy, retain_accuracy=retain_accuracy)\n",
    "\n",
    "        if test_loss > forget_loss:\n",
    "            break\n",
    "\n",
    "run_logger.info(f'NegGrad unlearning complete: save_file={SAVE_FILE}, train_loss={train_loss}, train_accuracy={train_accuracy}, test_loss={test_loss}, test_accuracy={test_accuracy}')\n",
    "torch.save(model, SAVE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b161eb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import eval\n",
    "\n",
    "from orthograd import OrthogonalGrad, AdamUpdateDirection\n",
    "from tqdm import tqdm\n",
    "\n",
    "SAVE_FILE = 'weights/modelOG10000.pth'\n",
    "EPOCHS = 200\n",
    "EVAL_EVERY = 5\n",
    "\n",
    "model.to('cuda')\n",
    "model.train()\n",
    "\n",
    "test_loss = None\n",
    "test_accuracy = None\n",
    "\n",
    "optimizer_retain = AdamUpdateDirection(model.parameters())\n",
    "optimizer_forget = AdamUpdateDirection(model.parameters())\n",
    "\n",
    "unlearn_method = OrthogonalGrad(\n",
    "    lr=LEARNING_RATE,\n",
    "    loss=criterion,\n",
    "    optimizer_retain=optimizer_retain,\n",
    "    optimizer_unlearn=optimizer_forget,\n",
    "    retain_grad_mode='per_sample',\n",
    "    update_mode='both',\n",
    "    original_model=model,\n",
    "    grad_mask=None,\n",
    "    alpha=0.5,\n",
    ")\n",
    "\n",
    "# NegGrad unlearning\n",
    "with tqdm(range(EPOCHS), unit='epoch', desc='retain_accuracy=None, forget_accuracy=None, test_accuracy=None, retain_loss=None, forget_loss=None, test_loss=None') as pbar:\n",
    "    for epoch in pbar:\n",
    "        retain_running_loss, forget_running_loss = 0.0, 0.0\n",
    "        retain_correct_predictions, forget_correct_predictions = 0, 0\n",
    "        retain_total_predictions, forget_total_predictions = 0, 0\n",
    "        model.train() # Set the model to training mode\n",
    "\n",
    "        for (retain_inputs, retain_labels), (forget_inputs, forget_labels) in zip(train_dataloader, unlearn_dataloader):\n",
    "            # Move inputs and labels to the specified device\n",
    "            retain_inputs, retain_labels = retain_inputs.to('cuda'), retain_labels.to('cuda')\n",
    "            forget_inputs, forget_labels = forget_inputs.to('cuda'), forget_labels.to('cuda')\n",
    "\n",
    "            # Compute predictions\n",
    "            retain_outputs = model(retain_inputs)\n",
    "            forget_outputs = model(forget_inputs)\n",
    "            _, retain_predictions = torch.max(retain_outputs.data, 1)\n",
    "            _, forget_predictions = torch.max(forget_outputs.data, 1)\n",
    "\n",
    "            # Update the running total of correct predictions and samples\n",
    "            retain_correct_predictions += (retain_predictions == retain_labels).sum().item()\n",
    "            forget_correct_predictions += (forget_predictions == forget_labels).sum().item()\n",
    "            retain_total_predictions += retain_labels.size(0)\n",
    "            forget_total_predictions += forget_labels.size(0)\n",
    "\n",
    "            # Compute the loss and its gradients\n",
    "            forget_loss, retain_loss = unlearn_method(\n",
    "                model, forget_inputs, forget_labels, retain_inputs, retain_labels\n",
    "            )\n",
    "\n",
    "            retain_running_loss += retain_loss.item()\n",
    "            forget_running_loss += forget_loss.item()\n",
    "\n",
    "        # Calculate the average loss and accuracy\n",
    "        retain_avg_loss = retain_running_loss / len(train_dataloader)\n",
    "        forget_avg_loss = forget_running_loss / len(train_dataloader)\n",
    "        retain_accuracy = 100 * retain_correct_predictions / retain_total_predictions\n",
    "        forget_accuracy = 100 * forget_correct_predictions / forget_total_predictions\n",
    "        \n",
    "        test_loss, test_accuracy = eval.test(model, test_dataloader, criterion)\n",
    "\n",
    "        pbar.set_postfix(test_loss=test_loss, forget_loss=forget_loss, retain_loss=retain_loss, test_accuracy=test_accuracy, forget_accuracy=forget_accuracy, retain_accuracy=retain_accuracy)\n",
    "        \n",
    "        if test_loss > forget_loss:\n",
    "            break\n",
    "\n",
    "run_logger.info(f'OrthoGrad unlearning complete: save_file={SAVE_FILE}, train_loss={train_loss}, train_accuracy={train_accuracy}, test_loss={test_loss}, test_accuracy={test_accuracy}')\n",
    "torch.save(model, SAVE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb13f8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import eval\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm\n",
    "from gdr_gma import MemoryBank, get_gradient, rectify_graident\n",
    "\n",
    "SAVE_FILE = 'weights/modelGG10000.pth'\n",
    "EPOCHS = 200\n",
    "EVAL_EVERY = 5\n",
    "\n",
    "model.to('cuda')\n",
    "model.train()\n",
    "\n",
    "test_loss = None\n",
    "test_accuracy = None\n",
    "\n",
    "batches = math.ceil(len(zip(train_dataloader, unlearn_dataloader)) / BATCH_SIZE)\n",
    "bank = MemoryBank(size=batches)\n",
    "\n",
    "# NegGrad unlearning\n",
    "with tqdm(range(EPOCHS), unit='epoch', desc='retain_accuracy=None, forget_accuracy=None, test_accuracy=None, retain_loss=None, forget_loss=None, test_loss=None') as pbar:\n",
    "    for epoch in pbar:\n",
    "        retain_running_loss, forget_running_loss = 0.0, 0.0\n",
    "        retain_correct_predictions, forget_correct_predictions = 0, 0\n",
    "        retain_total_predictions, forget_total_predictions = 0, 0\n",
    "\n",
    "        for (retain_inputs, retain_labels), (forget_inputs, forget_labels) in zip(train_dataloader, unlearn_dataloader):\n",
    "            # Move inputs and labels to the specified device\n",
    "            retain_inputs, retain_labels = retain_inputs.to('cuda'), retain_labels.to('cuda')\n",
    "            forget_inputs, forget_labels = forget_inputs.to('cuda'), forget_labels.to('cuda')\n",
    "\n",
    "            # Compute predictions\n",
    "            retain_outputs = model(retain_inputs)\n",
    "            forget_outputs = model(forget_inputs)\n",
    "            _, retain_predictions = torch.max(retain_outputs.data, 1)\n",
    "            _, forget_predictions = torch.max(forget_outputs.data, 1)\n",
    "\n",
    "            # Update the running total of correct predictions and samples\n",
    "            retain_correct_predictions += (retain_predictions == retain_labels).sum().item()\n",
    "            forget_correct_predictions += (forget_predictions == forget_labels).sum().item()\n",
    "            retain_total_predictions += retain_labels.size(0)\n",
    "            forget_total_predictions += forget_labels.size(0)\n",
    "\n",
    "            # Compute the loss and its gradients\n",
    "            retain_loss = criterion(retain_outputs, retain_labels)\n",
    "            forget_loss = criterion(forget_outputs, forget_labels)\n",
    "            retain_running_loss += retain_loss.item()\n",
    "            forget_running_loss += forget_loss.item()\n",
    "\n",
    "            retain_loss.backward()\n",
    "            retain_grads = get_gradient(model)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            (-1.0 * forget_loss).backward()\n",
    "            forget_grads = get_gradient(model)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            rectified_retain_grads, rectified_forget_grads = rectify_graident(retain_grads, forget_grads)\n",
    "            if epoch > 0 and bank.mean_grads(rectified_forget_grads[-1]) != None:\n",
    "                grads, _ = rectify_graident([rectified_forget_grads[-1]], [bank.mean_grads(rectified_forget_grads[-1])])\n",
    "                rectified_forget_grads[-1] = grads[-1]\n",
    "                \n",
    "            with torch.no_grad():\n",
    "                    gamma, epsilon = 100, 0.02\n",
    "                    lambda_weight = 1/(1+torch.exp(gamma*(retain_loss-epsilon)))\n",
    "\n",
    "            idx = 0\n",
    "            \n",
    "            for _, param in model.named_parameters():\n",
    "                if param.requires_grad:\n",
    "                    param.grad =  ((1-lambda_weight)*rectified_retain_grads[idx]+lambda_weight*rectified_forget_grads[idx]).view(param.size())\n",
    "                    idx += 1\n",
    "\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # Calculate the average loss and accuracy\n",
    "        retain_loss = retain_running_loss / len(train_dataloader)\n",
    "        forget_loss = forget_running_loss / len(train_dataloader)\n",
    "        retain_accuracy = 100 * retain_correct_predictions / retain_total_predictions\n",
    "        forget_accuracy = 100 * forget_correct_predictions / forget_total_predictions\n",
    "        \n",
    "        test_loss, test_accuracy = eval.test(model, test_dataloader, criterion)\n",
    "\n",
    "        pbar.set_postfix(test_loss=test_loss, forget_loss=forget_loss, retain_loss=retain_loss, test_accuracy=test_accuracy, forget_accuracy=forget_accuracy, retain_accuracy=retain_accuracy)\n",
    "\n",
    "        if test_loss > forget_loss:\n",
    "            break\n",
    "\n",
    "run_logger.info(f'GDR-GMA unlearning complete: save_file={SAVE_FILE}, train_loss={train_loss}, train_accuracy={train_accuracy}, test_loss={test_loss}, test_accuracy={test_accuracy}')\n",
    "torch.save(model, SAVE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075e2777",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhessian import hessian\n",
    "\n",
    "HESSIAN_MAX_ITER = 10\n",
    "HESSIAN_TOP_N = 3\n",
    "\n",
    "for blk in model.blocks:\n",
    "    blk.attn.fused_attn = False\n",
    "\n",
    "hessian_comp = hessian(model,\n",
    "                        criterion,\n",
    "                        dataloader=train_dataloader,\n",
    "                        cuda=torch.device('cuda'))\n",
    "\n",
    "top_eigenvalues, _ = hessian_comp.eigenvalues(maxIter=HESSIAN_MAX_ITER, top_n=HESSIAN_TOP_N) # Compute eigenvalues\n",
    "# trace = hessian_comp.trace() # Compute trace\n",
    "# density_eigen, density_weight = hessian_comp.density() # Compute density\n",
    "\n",
    "print(\"Hessian top eigenvalues: \", top_eigenvalues)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
